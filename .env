# FIXED llm_integration.py - Replace your existing file with this
# File: app/llm_integration.py

import os
import json
import requests
from datetime import datetime
from typing import Dict, List, Optional
from dotenv import load_dotenv

# Import the enhanced news fetcher
try:
    from news_fetcher import EnhancedNewsFetcher
    NEWS_FETCHER_AVAILABLE = True
except ImportError:
    NEWS_FETCHER_AVAILABLE = False
    print("âš ï¸ Enhanced news fetcher not available")

class LLMAnalyzer:
    """FIXED LLM-powered market analysis using OpenRouter with financial news integration"""
    
    def __init__(self):
        # FORCE RELOAD THE .ENV FILE
        load_dotenv(override=True)
        
        self.api_key = self._get_api_key()
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"
        
        # FIXED: Valid OpenRouter model names (as of 2024)
        self.models = [
            "meta-llama/llama-3.1-8b-instruct:free",      # Free Llama model
            "mistralai/mistral-7b-instruct:free",          # Free Mistral model  
            "google/gemma-7b-it:free",                     # Free Gemma model
            "meta-llama/llama-3.1-8b-instruct",           # Paid Llama (fallback)
            "openai/gpt-3.5-turbo",                       # Paid GPT (fallback)
        ]
        
        self.current_model = self.models[0]  # Start with first free model
        
        # Debug info
        print(f"ğŸ”‘ OpenRouter API Key check:")
        print(f"   API Key found: {self.api_key is not None}")
        if self.api_key:
            print(f"   Key starts with: {self.api_key[:20]}...")
            print(f"   Key length: {len(self.api_key)}")
            if not self.api_key.startswith('sk-or-v1-'):
                print("   âš ï¸ WARNING: API key doesn't start with 'sk-or-v1-'")
            else:
                print("   âœ… API key format looks correct")
            
            # Test the API key with multiple models
            self._test_api_connection()
        else:
            print("âŒ OPEN_ROUTER_KEY not found in environment variables")
    
    def _get_api_key(self):
        """Get API key with multiple fallback methods"""
        # Try multiple environment variable names
        key_names = ['OPEN_ROUTER_KEY', 'OPENROUTER_API_KEY', 'OPENROUTER_KEY']
        
        for key_name in key_names:
            api_key = os.getenv(key_name)
            if api_key:
                # Clean the API key
                cleaned_key = api_key.strip().strip('"').strip("'")
                print(f"âœ… Found API key in {key_name}")
                return cleaned_key
        
        # Also try os.environ directly
        for key_name in key_names:
            api_key = os.environ.get(key_name)
            if api_key:
                cleaned_key = api_key.strip().strip('"').strip("'")
                print(f"âœ… Found API key in os.environ {key_name}")
                return cleaned_key
        
        return None
    
    def _test_api_connection(self):
        """Test API connection with model fallback"""
        print("ğŸ§ª Testing OpenRouter API connection...")
        
        for i, model in enumerate(self.models):
            try:
                print(f"   Testing model {i+1}/{len(self.models)}: {model}")
                
                if self._test_single_model(model):
                    self.current_model = model
                    print(f"âœ… Successfully connected with model: {model}")
                    return True
                    
            except Exception as e:
                print(f"   âŒ Model {model} failed: {e}")
                continue
        
        print("âŒ All models failed - check API key, credits, or internet connection")
        return False
    
    def _test_single_model(self, model: str) -> bool:
        """Test a specific model with a minimal request"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://trading-bot.local",
            "X-Title": "Crypto Trading Bot"
        }
        
        test_data = {
            "model": model,
            "messages": [{"role": "user", "content": "Hi"}],
            "max_tokens": 5,
            "temperature": 0.1
        }
        
        response = requests.post(
            self.base_url,
            headers=headers,
            json=test_data,
            timeout=15
        )
        
        if response.status_code == 200:
            return True
        elif response.status_code == 401:
            print(f"      401 Unauthorized - API key issue")
            return False
        elif response.status_code == 402:
            print(f"      402 Payment Required - insufficient credits")
            return False
        elif response.status_code == 404:
            print(f"      404 Not Found - model not available: {model}")
            return False
        else:
            print(f"      {response.status_code} Error: {response.text}")
            return False
    
    def analyze_market_sentiment(self, price_data: Dict, technical_analysis: Dict) -> Dict:
        """Get LLM analysis of market conditions"""
        if not self.api_key:
            return {"analysis": "LLM not available - missing API key", "confidence": 0}
        
        try:
            # Prepare market data for LLM
            prompt = self._create_market_analysis_prompt(price_data, technical_analysis)
            
            # Get LLM response
            response = self._call_llm(prompt)
            
            if not response:
                return {"analysis": "LLM API call failed", "confidence": 0}
            
            # Parse LLM response
            analysis = self._parse_llm_response(response)
            
            return analysis
            
        except Exception as e:
            print(f"âŒ LLM analysis error: {e}")
            return {"analysis": f"LLM error: {str(e)}", "confidence": 0}
    
    def analyze_financial_news_sentiment(self, news_headlines: List[str], technical_analysis: Dict) -> Dict:
        """Enhanced analysis using financial news headlines"""
        if not self.api_key:
            return {"analysis": "Financial news analysis not available - missing API key", "confidence": 0}
            
        if not news_headlines:
            return {"analysis": "No financial news headlines provided", "confidence": 0}
        
        try:
            # Create enhanced prompt with financial news data
            prompt = self._create_financial_news_analysis_prompt(news_headlines, technical_analysis)
            
            # Get LLM response
            response = self._call_llm(prompt)
            
            if not response:
                return {"analysis": "Financial news LLM API call failed", "confidence": 0}
            
            # Parse LLM response
            analysis = self._parse_llm_response(response)
            
            # Add financial news specific fields
            analysis['news_sentiment'] = analysis.get('llm_sentiment', 'Neutral')
            analysis['news_confidence'] = analysis.get('llm_confidence', 50)
            analysis['source_breakdown'] = self._analyze_news_sources(news_headlines)
            analysis['sentiment_indicators'] = self._detect_sentiment_patterns(news_headlines)
            
            return analysis
            
        except Exception as e:
            print(f"âŒ Financial news LLM analysis error: {e}")
            return {"analysis": f"Financial news analysis error: {str(e)}", "confidence": 0}
    
    def _create_market_analysis_prompt(self, price_data: Dict, technical_analysis: Dict) -> str:
        """Create a simplified prompt for more reliable parsing"""
        
        current_price = price_data.get('price', 0)
        trend = technical_analysis.get('trend', 'unknown')
        rsi = technical_analysis.get('indicators', {}).get('rsi', 50)
        signals = technical_analysis.get('signals', [])
        
        prompt = f"""Analyze Bitcoin market conditions:

Price: ${current_price:,.2f}
Trend: {trend}
RSI: {rsi:.1f}
Signals: {', '.join(signals) if signals else 'None'}

Provide analysis as simple JSON:
{{
"sentiment": "Bullish",
"recommendation": "HOLD",
"confidence": 75,
"risk_level": "High",
"reasoning": "Brief analysis in one sentence"
}}

Rules:
- sentiment: Bullish, Bearish, or Neutral
- recommendation: BUY, SELL, or HOLD
- confidence: 0-100 number
- risk_level: Low, Medium, or High
- reasoning: Keep under 100 characters

Consider: RSI >70 = overbought, RSI <30 = oversold, Price >$100k = high risk."""

        return prompt
    
    def _create_financial_news_analysis_prompt(self, headlines: List[str], technical_analysis: Dict) -> str:
        """Create prompt that includes financial news sentiment"""
        
        current_price = technical_analysis.get('price', 0)
        trend = technical_analysis.get('trend', 'unknown')
        rsi = technical_analysis.get('indicators', {}).get('rsi', 50)
        
        # Group headlines by source
        polygon_headlines = [h for h in headlines if '[Polygon.io]' in h]
        coindesk_headlines = [h for h in headlines if '[CoinDesk]' in h]
        alpaca_headlines = [h for h in headlines if '[Alpaca]' in h]
        
        prompt = f"""Analyze Bitcoin market using technical data + financial news sentiment:

TECHNICAL DATA:
- Price: ${current_price:,.2f}
- Trend: {trend}
- RSI: {rsi:.1f}

FINANCIAL NEWS HEADLINES:

Polygon.io News ({len(polygon_headlines)} items):
{chr(10).join(polygon_headlines[:5])}

CoinDesk News ({len(coindesk_headlines)} items):
{chr(10).join(coindesk_headlines[:5])}

Alpaca News ({len(alpaca_headlines)} items):
{chr(10).join(alpaca_headlines[:5])}

Provide analysis as JSON:
{{
"sentiment": "Bullish/Bearish/Neutral",
"recommendation": "BUY/SELL/HOLD",
"confidence": 75,
"risk_level": "Low/Medium/High",
"news_sentiment": "Bullish/Bearish/Neutral",
"news_confidence": 80,
"source_analysis": {{
  "polygon": "sentiment",
  "coindesk": "sentiment", 
  "alpaca": "sentiment"
}},
"key_themes": ["institutional adoption", "technical analysis"],
"reasoning": "Combined technical and financial news analysis"
}}

Focus on:
- News sentiment vs price action alignment
- Institutional vs retail sentiment indicators
- Technical confirmation of news-driven moves
- Risk factors from regulatory or market news"""

        return prompt
    
    def _call_llm(self, prompt: str) -> Optional[str]:
        """Make API call to OpenRouter - FIXED VERSION"""
        if not self.api_key:
            print("âŒ No OpenRouter API key available")
            return None
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://trading-bot.local",
            "X-Title": "Crypto Trading Bot"
        }
        
        data = {
            "model": self.current_model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.1,
            "max_tokens": 800,
            "top_p": 0.9
        }
        
        print(f"ğŸ¤– Calling OpenRouter API with model: {self.current_model}")
        
        try:
            response = requests.post(
                self.base_url,
                headers=headers,
                json=data,
                timeout=30
            )
            
            print(f"ğŸ¤– OpenRouter response status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                return self._clean_response(content)
                
            elif response.status_code == 401:
                print("âŒ 401 Unauthorized - Invalid API key")
                return None
                
            elif response.status_code == 402:
                print("âŒ 402 Payment Required - Insufficient credits")
                # Try to fall back to next free model
                if self._fallback_to_free_model():
                    return self._call_llm(prompt)  # Retry with new model
                return None
                
            elif response.status_code == 404:
                print(f"âŒ 404 Model not found: {self.current_model}")
                # Try to fall back to next model
                if self._fallback_to_next_model():
                    return self._call_llm(prompt)  # Retry with new model
                return None
                
            else:
                error_text = response.text
                print(f"âŒ OpenRouter API Error {response.status_code}: {error_text}")
                return None
                
        except requests.exceptions.Timeout:
            print("âŒ OpenRouter API timeout")
            return None
        except requests.exceptions.RequestException as e:
            print(f"âŒ Request exception: {e}")
            return None
        except Exception as e:
            print(f"âŒ Unexpected error calling LLM: {e}")
            return None
    
    def _fallback_to_free_model(self) -> bool:
        """Try to fallback to a free model"""
        free_models = [m for m in self.models if ':free' in m]
        for model in free_models:
            if model != self.current_model:
                print(f"ğŸ”„ Falling back to free model: {model}")
                if self._test_single_model(model):
                    self.current_model = model
                    return True
        return False
    
    def _fallback_to_next_model(self) -> bool:
        """Try to fallback to the next available model"""
        try:
            current_index = self.models.index(self.current_model)
            for i in range(current_index + 1, len(self.models)):
                next_model = self.models[i]
                print(f"ğŸ”„ Falling back to model: {next_model}")
                if self._test_single_model(next_model):
                    self.current_model = next_model
                    return True
        except ValueError:
            pass
        return False
    
    def _parse_llm_response(self, response: str) -> Dict:
        """Parse LLM response and extract structured data"""
        try:
            # First try simple JSON extraction
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = response[start_idx:end_idx]
                
                # Try to parse JSON
                try:
                    analysis = json.loads(json_str)
                    
                    # Validate and return if successful
                    if isinstance(analysis, dict):
                        return {
                            'llm_sentiment': analysis.get('sentiment', 'Neutral'),
                            'llm_recommendation': analysis.get('recommendation', 'HOLD'),
                            'llm_confidence': analysis.get('confidence', 50),
                            'llm_risk_level': analysis.get('risk_level', 'Medium'),
                            'llm_reasoning': analysis.get('reasoning', ''),
                            'llm_news_sentiment': analysis.get('news_sentiment', 'Neutral'),
                            'llm_news_confidence': analysis.get('news_confidence', 50),
                            'llm_source_analysis': analysis.get('source_analysis', {}),
                            'llm_key_themes': analysis.get('key_themes', []),
                            'llm_raw_response': response[:300] + '...' if len(response) > 300 else response
                        }
                except json.JSONDecodeError:
                    pass  # Will fall through to text parsing
            
            # Fallback: extract key information using simple text parsing
            return self._simple_text_parse(response)
            
        except Exception as e:
            print(f"âš ï¸ Error parsing LLM response: {e}")
            return {
                'llm_sentiment': 'Neutral',
                'llm_recommendation': 'HOLD',
                'llm_confidence': 30,
                'llm_reasoning': 'LLM response parsing failed',
                'llm_raw_response': response[:200] + '...' if len(response) > 200 else response
            }
    
    def _simple_text_parse(self, response: str) -> Dict:
        """Simple text parsing when JSON fails"""
        response_lower = response.lower()
        
        # Extract recommendation
        if 'buy' in response_lower and 'sell' not in response_lower:
            recommendation = 'BUY'
        elif 'sell' in response_lower and 'buy' not in response_lower:
            recommendation = 'SELL'
        else:
            recommendation = 'HOLD'
        
        # Extract sentiment
        if 'bullish' in response_lower:
            sentiment = 'Bullish'
        elif 'bearish' in response_lower:
            sentiment = 'Bearish'
        else:
            sentiment = 'Neutral'
        
        # Extract confidence (look for numbers)
        import re
        confidence_match = re.search(r'(\d+)%?', response)
        confidence = int(confidence_match.group(1)) if confidence_match else 50
        confidence = max(0, min(100, confidence))  # Clamp between 0-100
        
        # Extract risk level
        risk_level = 'Medium'
        if 'high risk' in response_lower or 'extreme' in response_lower:
            risk_level = 'High'
        elif 'low risk' in response_lower:
            risk_level = 'Low'
        
        return {
            'llm_sentiment': sentiment,
            'llm_recommendation': recommendation,
            'llm_confidence': confidence,
            'llm_risk_level': risk_level,
            'llm_reasoning': response[:200] + '...' if len(response) > 200 else response,
            'llm_raw_response': response
        }
    
    def _clean_response(self, response: str) -> str:
        """Clean response text to fix parsing issues"""
        import re
        
        # Remove control characters (ASCII 0-31 except newline, tab, carriage return)
        cleaned = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', response)
        
        # Replace problematic characters
        cleaned = cleaned.replace('\n', ' ')  # Replace newlines with spaces
        cleaned = cleaned.replace('\t', ' ')  # Replace tabs with spaces
        cleaned = re.sub(r'\s+', ' ', cleaned)  # Collapse multiple spaces
        
        # Remove any remaining problematic characters for JSON
        cleaned = ''.join(char for char in cleaned if ord(char) >= 32 or char in ['\n', '\t'])
        
        return cleaned.strip()
    
    def _analyze_news_sources(self, headlines: List[str]) -> Dict:
        """Analyze sentiment by news source"""
        source_sentiment = {
            'polygon': {'positive': 0, 'negative': 0, 'neutral': 0},
            'coindesk': {'positive': 0, 'negative': 0, 'neutral': 0},
            'alpaca': {'positive': 0, 'negative': 0, 'neutral': 0}
        }
        
        positive_keywords = ['bull', 'bullish', 'rise', 'up', 'gain', 'profit', 'positive', 'adoption', 'breakthrough']
        negative_keywords = ['bear', 'bearish', 'fall', 'down', 'loss', 'negative', 'crash', 'decline', 'concern']
        
        for headline in headlines:
            headline_lower = headline.lower()
            
            # Determine source
            source = None
            if '[polygon.io]' in headline_lower:
                source = 'polygon'
            elif '[coindesk]' in headline_lower:
                source = 'coindesk'
            elif '[alpaca]' in headline_lower:
                source = 'alpaca'
            
            if source:
                # Analyze sentiment
                positive_score = sum(1 for word in positive_keywords if word in headline_lower)
                negative_score = sum(1 for word in negative_keywords if word in headline_lower)
                
                if positive_score > negative_score:
                    source_sentiment[source]['positive'] += 1
                elif negative_score > positive_score:
                    source_sentiment[source]['negative'] += 1
                else:
                    source_sentiment[source]['neutral'] += 1
        
        return source_sentiment
    
    def _detect_sentiment_patterns(self, headlines: List[str]) -> List[str]:
        """Detect sentiment patterns in financial news"""
        sentiment_indicators = []
        
        # Count sentiment emojis
        bullish_count = sum(1 for h in headlines if 'ğŸ“ˆ' in h)
        bearish_count = sum(1 for h in headlines if 'ğŸ“‰' in h)
        neutral_count = sum(1 for h in headlines if 'â¡ï¸' in h)
        
        total_headlines = len(headlines)
        if total_headlines > 0:
            if bullish_count / total_headlines > 0.6:
                sentiment_indicators.append("Strong bullish news sentiment")
            elif bearish_count / total_headlines > 0.6:
                sentiment_indicators.append("Strong bearish news sentiment")
            elif neutral_count / total_headlines > 0.7:
                sentiment_indicators.append("Neutral market news")
        
        # Check for institutional keywords
        institutional_keywords = ['institutional', 'corporate', 'etf', 'regulation', 'sec', 'federal']
        institutional_mentions = sum(1 for h in headlines for keyword in institutional_keywords if keyword in h.lower())
        
        if institutional_mentions > 2:
            sentiment_indicators.append("High institutional focus")
        
        # Check for technical analysis mentions
        technical_keywords = ['technical', 'resistance', 'support', 'pattern', 'chart']
        technical_mentions = sum(1 for h in headlines for keyword in technical_keywords if keyword in h.lower())
        
        if technical_mentions > 1:
            sentiment_indicators.append("Technical analysis focus")
        
        return sentiment_indicators[:5]  # Top 5 indicators
    
    def analyze_news_sentiment(self, news_headlines: List[str]) -> Dict:
        """Analyze news sentiment impact on Bitcoin"""
        if not self.api_key or not news_headlines:
            return {"news_sentiment": "Neutral", "impact": "Low"}
        
        try:
            headlines_text = '\n'.join(f"- {headline}" for headline in news_headlines[:10])
            
            prompt = f"""Analyze the sentiment of these recent Bitcoin/cryptocurrency financial news headlines and their potential market impact:

{headlines_text}

Provide analysis in JSON format:
{{
  "overall_sentiment": "Bullish/Bearish/Neutral",
  "impact_level": "Low/Medium/High",
  "key_themes": ["theme1", "theme2"],
  "market_impact": "Brief explanation of likely price impact",
  "confidence": 75
}}"""

            response = self._call_llm(prompt)
            
            if not response:
                return {"news_sentiment": "Neutral", "impact": "Low"}
                
            analysis = self._parse_llm_response(response)
            
            return {
                'news_sentiment': analysis.get('llm_sentiment', 'Neutral'),
                'news_impact': analysis.get('llm_confidence', 50),
                'news_reasoning': analysis.get('llm_reasoning', '')
            }
            
        except Exception as e:
            print(f"âŒ News sentiment analysis error: {e}")
            return {"news_sentiment": "Neutral", "impact": "Low"}
    
    def get_risk_assessment(self, portfolio_data: Dict, market_data: Dict) -> Dict:
        """Get LLM-based risk assessment"""
        if not self.api_key:
            return {"risk_level": "Medium", "suggestions": []}
        
        try:
            prompt = f"""As a risk management expert, assess the current trading risk based on:

PORTFOLIO:
- Current Position: {portfolio_data.get('position_type', 'None')}
- Position Size: {portfolio_data.get('position_size', 0)}
- Unrealized PnL: {portfolio_data.get('unrealized_pnl', 0)}
- Available Balance: {portfolio_data.get('available_balance', 0)}

MARKET CONDITIONS:
- Price: ${market_data.get('price', 0):,.2f}
- Volatility: {market_data.get('volatility', 'Unknown')}
- Trend: {market_data.get('trend', 'Unknown')}

Provide risk assessment in JSON format:
{{
  "risk_level": "Low/Medium/High/Extreme",
  "risk_score": 65,
  "risk_factors": ["factor1", "factor2"],
  "recommendations": ["action1", "action2"],
  "position_sizing": "Suggested position size guidance",
  "stop_loss": "Stop loss recommendation"
}}"""

            response = self._call_llm(prompt)
            
            if not response:
                return {"risk_level": "Medium", "suggestions": []}
                
            return self._parse_llm_response(response)
            
        except Exception as e:
            print(f"âŒ Risk assessment error: {e}")
            return {"risk_level": "Medium", "suggestions": []}

# Enhanced NewsFetcher integration - backward compatibility
class NewsFetcher:
    """News fetcher class for backward compatibility"""
    
    def __init__(self):
        if NEWS_FETCHER_AVAILABLE:
            try:
                self.enhanced_fetcher = EnhancedNewsFetcher()
                print("âœ… Enhanced news fetcher initialized")
            except Exception as e:
                print(f"âš ï¸ Enhanced news fetcher initialization failed: {e}")
                self.enhanced_fetcher = None
        else:
            self.enhanced_fetcher = None
            print("âš ï¸ Enhanced news fetcher not available")
    
    def get_bitcoin_news(self, limit: int = 15) -> List[str]:
        """Get Bitcoin news from financial sources"""
        if self.enhanced_fetcher:
            try:
                return self.enhanced_fetcher.get_bitcoin_news(limit)
            except Exception as e:
                print(f"âŒ Enhanced news fetch error: {e}")
                return self._get_fallback_headlines()
        else:
            return self._get_fallback_headlines()
    
    def get_news_sentiment_summary(self) -> Dict:
        """Get news sentiment summary"""
        if self.enhanced_fetcher:
            try:
                return self.enhanced_fetcher.get_news_sentiment_summary()
            except Exception as e:
                print(f"âŒ Enhanced news sentiment error: {e}")
                return {'overall_sentiment': 'Neutral', 'confidence': 50}
        else:
            return {'overall_sentiment': 'Neutral', 'confidence': 50}
    
    def _get_fallback_headlines(self) -> List[str]:
        """Fallback headlines when enhanced fetcher is unavailable"""
        return [
            "[Financial] Bitcoin consolidates above key support levels ğŸ“ˆ",
            "[Financial] Cryptocurrency market shows institutional interest â¡ï¸",
            "[Financial] Technical indicators suggest potential breakout ğŸ“ˆ",
            "[Financial] Regulatory clarity discussions continue in markets â¡ï¸",
            "[Financial] Bitcoin network fundamentals remain strong ğŸ“ˆ"
        ]

# Test function
def test_openrouter_connection():
    """Test the OpenRouter connection with improved error handling"""
    print("ğŸ§ª Testing OpenRouter LLM Integration...")
    
    analyzer = LLMAnalyzer()
    
    if not analyzer.api_key:
        print("âŒ Test failed: No API key found")
        print("ğŸ’¡ Solution: Add OPEN_ROUTER_KEY=sk-or-v1-your-key-here to your .env file")
        return False
    
    # Test with sample data
    price_data = {'price': 95000}
    technical_analysis = {
        'trend': 'bullish',
        'signals': ['RSI_OVERSOLD'],
        'indicators': {'rsi': 35, 'macd': 150}
    }
    
    print("\nğŸ“Š Testing market sentiment analysis...")
    result = analyzer.analyze_market_sentiment(price_data, technical_analysis)
    
    if 'llm_sentiment' in result:
        print(f"âœ… LLM Analysis successful!")
        print(f"   Sentiment: {result.get('llm_sentiment', 'Unknown')}")
        print(f"   Recommendation: {result.get('llm_recommendation', 'Unknown')}")
        print(f"   Confidence: {result.get('llm_confidence', 0)}%")
        return True
    else:
        print(f"âŒ LLM Analysis failed: {result}")
        return False

# Usage example and testing
if __name__ == "__main__":
    # Test the FIXED LLM integration
    test_openrouter_connection()
    
    # Test news integration
    news_fetcher = NewsFetcher()
    headlines = news_fetcher.get_bitcoin_news()
    
    print("\nğŸ“° Financial News Headlines:")
    for i, headline in enumerate(headlines[:5], 1):
        print(f"{i}. {headline}")
    
    print(f"\nğŸ“Š News Sentiment: {news_fetcher.get_news_sentiment_summary()}")
